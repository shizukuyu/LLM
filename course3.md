## RAG概述

- 简单来说rag就是在已训练好大模型的基础上增加一个外部数据库，使llm生成的内容在垂直领域达到相应的效果
- 主要目的是降本增效

![31](image/31.png)

### 可以解决的问题

- 幻觉
- 过时知识
- 缺乏透明和可追溯的推理过程


### 基础效果对比

![32](image/32.png)


## RAG工作原理

![33](image/33.png)

- Indexing
    - docs to Vetor-DB
    Similarity check: cosine distance, dot product

![34](image/34.png)

- Retrieval
- Generation

## RAG发展历程

![35](image/35.png)

- Naive
- Advanced
- Modular

## RAG常见优化方法

![36](image/36.png)

## RAG vs Fine-Tuning

总的来说RAG更加灵活和动态，Fine-tuning高度专业化

![37](image/37.png)

## RAG总结

这个图做的可真好，赏心悦目呢！

![38](image/38.png)


## 作业

- 复制环境，运行虚拟环境

![39](image/39.png)

- 装额外的包

![391](image/391.png)

- config里各种model设置好了

![392](image/392.png)

- 创建知识库，回答和拒答的案例问题

![393](image/393.png)

- 测试拒答流程

![394](image/394.png)

- 第一个问题成功了，第二个拒答了

![395](image/395.png)
![396](image/396.png)

### 测试huixiangdou

- 第一个问题huixiangdou是什么，运行之后直接展示了如何从分析问题到最后给出答案，流程还是挺有意思的，把最简易的框架贴在了这里。可以看到最后的分数是8，相对较高

    Q:有主题的疑问句，结果用 0～10 表示。直接提供得分不要解释。判断标准：有主语谓语宾语并且是疑问句得 10 分；缺少主谓宾扣分；陈述句直接得 0 分；不是疑问句直接得 0 分。直接提供得分不要解释
    
    A:根据您提供的内容，我无法判断"huixiangdou 是什么？" 这个句子的主题，因为它不包含任何有关于主题的信息。所以，我无法给出 0～10 的分数。请提供更具体的信息，以便我能够更准确地评估。

    Q:告诉我这句话的主题，直接说主题不要解释：“huixiangdou 是什么？ A:主题："huixiangdou" 的含义或定义。

    query:主题："huixiangdou" 的含义或定义。 top1 file:README.md

    Q:flooding, see arxiv2401.08772”

    请仔细阅读以上内容，判断问题和材料的关联度，用0～10表示。判断标准：非常相关得 10 分；完全没关联得 0 分。直接提供得分不要解释。 A:8

![397](image/397.png)

![398](image/398.png)

- 第三个问题因为跟主题不相关所以没有答案

    Q:有主题的疑问句，结果用 0～10 表示。直接提供得分不要解释。

    判断标准：有主语谓语宾语并且是疑问句得 10 分；缺少主谓宾扣分；陈述句直接得 0 分；不是疑问句直接得 0 分。直接提供得分不要解释 A:根据给定的标准，"今天天气怎么样？" 是一个有主语、谓语和宾语，并且是疑问句的句子。因此，它的得分是 10 分。

    Q:告诉我这句话的主题，直接说主题不要解释：“今天天气怎么样？ A:主题：天气。 

    ErrorCode.UNRELATED, 今天天气怎么样？, , ['HuixiangDou.pdf']

![399](image/399.png)


